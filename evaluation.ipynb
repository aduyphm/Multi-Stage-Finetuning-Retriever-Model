{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d094f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    PreTrainedTokenizerFast,\n",
    "    DataCollatorWithPadding,\n",
    "    BatchEncoding\n",
    ")\n",
    "from transformers import AutoModel, AutoTokenizer, BatchEncoding, PreTrainedTokenizerFast\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "from typing import List\n",
    "from sklearn.metrics import ndcg_score\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035b4e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path=\"checkpoints/biencoder_2023-09-18-1901.46\"\n",
    "legal_corpus_path=\"data/sent_truncated_vbpl_update.csv\"\n",
    "test_path=\"data/dvc_test.json\"\n",
    "index_path=\"me5_small_0919.index\"\n",
    "q_max_length=32\n",
    "p_max_length=144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "439c50b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu các văn bản\n",
    "vbpl = pd.read_csv(legal_corpus_path, encoding='utf-16')\n",
    "vbpl = vbpl.dropna().reset_index(drop=True)\n",
    "passages: List[str] = vbpl['truncated_text'].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d59d0d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu test\n",
    "with open(test_path, 'r') as file:\n",
    "    train = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a8cee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(model_name_or_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f9b02e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_normalize(x: torch.Tensor):\n",
    "    return torch.nn.functional.normalize(x, p=2, dim=-1)\n",
    "\n",
    "def encode_query(tokenizer: PreTrainedTokenizerFast, query: str) -> BatchEncoding:\n",
    "    return tokenizer(query,\n",
    "                     max_length=p_max_length,\n",
    "                     padding=True,\n",
    "                     truncation=True,\n",
    "                     return_tensors='pt')\n",
    "\n",
    "def encode_passage(tokenizer: PreTrainedTokenizerFast, passage: str, title: str = \"\") -> BatchEncoding:\n",
    "    return tokenizer(title,\n",
    "                     text_pair=passage,\n",
    "                     max_length=144,\n",
    "                     padding=True,\n",
    "                     truncation=True,\n",
    "                     return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5fcff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "psg_embeddings = []\n",
    "for passage in tqdm(passages):\n",
    "    psg_batch_dict = encode_passage(tokenizer, passage)\n",
    "    outputs: BaseModelOutput = model(**psg_batch_dict, return_dict=True)\n",
    "    psg_embeddings.append(l2_normalize(outputs.last_hidden_state[0, 0, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b298e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_embeddings(embeddings):\n",
    "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    normalized_embeddings = embeddings / norms\n",
    "    return normalized_embeddings\n",
    "\n",
    "norm_psg_embeddings = normalize_embeddings(psg_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dde2dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatIP(model.get_sentence_embedding_dimension())\n",
    "index.add(norm_psg_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f2fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a47fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "index = faiss.read_index(index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3d2d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f2(precision, recall):        \n",
    "    return (5 * precision * recall) / (4 * precision + recall + 1e-20)\n",
    "def calculate_f1(precision, recall):        \n",
    "    return (precision * recall) / (precision + recall + 1e-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4858e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá với dữ liệu\n",
    "top_k = 500\n",
    "thresh = 0\n",
    "total_f1 = 0\n",
    "total_f2 = 0\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_map = 0\n",
    "total_ndcg = 0\n",
    "\n",
    "# Check\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for i, item in tqdm(enumerate(test)):\n",
    "    query = item[\"noi_dung_hoi\"]\n",
    "#     query = query[:-1] if query.endswith(\"?\") else query\n",
    "    relevant_articles = item[\"vb_lien_quan\"]\n",
    "    dict_relevant = {(article[\"so_hieu\"], article[\"dieu\"]) : article for article in relevant_articles}\n",
    "    actual_positive = len(relevant_articles)\n",
    "    \n",
    "    query_batch_dict = encode_query(tokenizer, query)\n",
    "    outputs: BaseModelOutput = model(**query_batch_dict, return_dict=True)\n",
    "    query_embedding = l2_normalize(outputs.last_hidden_state[0, 0, :])\n",
    "    normalized_query_embedding = query_embedding / np.linalg.norm(query_embedding)\n",
    "    scores, indices, embeddings = index.search_and_reconstruct(normalized_query_embedding, top_k)\n",
    "    hits = vbpl.iloc[indices[0]]\n",
    "    hits1 = hits.copy()\n",
    "    hits1['score'] = scores[0]\n",
    "    \n",
    "    true_positive_set = set()\n",
    "    false_positive_set = set()\n",
    "    num_hits = 0\n",
    "    average_precision = 0\n",
    "    actual_relevance = []\n",
    "      \n",
    "    for j, idx_pred in enumerate(hits.index, 1):\n",
    "        key = (hits.at[idx_pred, \"so_hieu\"], hits.at[idx_pred, \"dieu\"])\n",
    "        if key in dict_relevant:\n",
    "            actual_relevance.append(1)\n",
    "            true_positive_set.add(key)\n",
    "            num_hits += 1\n",
    "            average_precision += num_hits/j\n",
    "        else:\n",
    "            actual_relevance.append(0)\n",
    "            false_positive_set.add(key)\n",
    "\n",
    "    true_positive = len(true_positive_set)            \n",
    "    false_positive = len(false_positive_set)\n",
    "    \n",
    "    if num_hits != 0: \n",
    "        average_precision = average_precision/num_hits\n",
    "    \n",
    "    ndcg = ndcg_score([actual_relevance], [scores[0]], k=top_k)\n",
    "    \n",
    "    precision = true_positive/(true_positive + false_positive + 1e-20)\n",
    "    recall = true_positive/actual_positive\n",
    "    f1 = calculate_f1(precision, recall)\n",
    "    f2 = calculate_f2(precision, recall)\n",
    "    \n",
    "    total_precision += precision\n",
    "    total_recall += recall\n",
    "    total_f1 += f1\n",
    "    total_f2 += f2\n",
    "    total_map += average_precision\n",
    "    total_ndcg += ndcg\n",
    "    \n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5fb542",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(test)\n",
    "print(f\"Recall: {total_recall/N}\")\n",
    "print(f\"Precision: {total_precision/N}\")\n",
    "print(f\"F2: {total_f2/N}\")\n",
    "print(f\"F1: {total_f1/N}\")\n",
    "print(f\"MAP: {total_map/N}\")\n",
    "print(f\"NDCG: {total_ndcg/N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab7a504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
